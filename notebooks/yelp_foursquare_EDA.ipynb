{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from geopy.distance import great_circle\n",
    "from geopy.point import Point\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster   latitude  longitude\n",
      "0        0  43.684513 -79.373033\n",
      "1        1  43.665939 -79.311547\n",
      "2        2  43.691500 -79.294351\n",
      "3        3  43.655026 -79.393131\n",
      "4        4  43.762444 -79.500654\n"
     ]
    }
   ],
   "source": [
    "# Extract csv data for get the long and lat\n",
    "df = pd.read_csv(\"../data/bike_stations.csv\")\n",
    "\n",
    "# Extract coordinates\n",
    "coords = df[['latitude', 'longitude']].to_numpy()\n",
    "\n",
    "# Convert meters to radians (for DBSCAN with haversine distance)\n",
    "kms_per_radian = 6371.0088\n",
    "epsilon = 0.5 / kms_per_radian  # 0.5 km = 500 meters\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "db = DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree', metric='haversine')\n",
    "df['cluster'] = db.fit_predict(np.radians(coords))\n",
    "\n",
    "# print(\"Clusters assigned:\")\n",
    "# print(df[['name', 'latitude', 'longitude', 'cluster']].head())\n",
    "# Mean coordinates per cluster\n",
    "cluster_centroids = df.groupby('cluster')[['latitude', 'longitude']].mean().reset_index()\n",
    "print(cluster_centroids.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Foursquare with a small radius (1000m) for all the bike stations in your city of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foursquare_places(lat, lon, radius=500, category=\"13065\"):  # Food & Drink category\n",
    "    api_key = os.getenv('FOURSQUARE_API_KEY')\n",
    "    url = \"https://places-api.foursquare.com/places/search\"\n",
    "    # url = \"https://api.foursquare.com/v3/places/search\"\n",
    "    headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"X-Places-API-Version\": '2025-06-17'  # Use this format, not a future date\n",
    "}\n",
    "    params = {\n",
    "        \"ll\": f\"{lat},{lon}\",\n",
    "        \"radius\": radius,\n",
    "        \"categories\": category,\n",
    "        \"limit\": 50\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"results\", [])\n",
    "    else:\n",
    "        print(f\"Foursquare API error at ({lat},{lon}): {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsq_pois = []\n",
    "#  Apply clustering (e.g., 10 clusters)\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "df['cluster'] = kmeans.fit_predict(coords)\n",
    "\n",
    "# Get centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "cluster_centroids = pd.DataFrame(centroids, columns=['latitude', 'longitude'])\n",
    "cluster_centroids['cluster'] = cluster_centroids.index\n",
    "\n",
    "for _, row in cluster_centroids.iterrows():\n",
    "    lat, lon = row['latitude'], row['longitude']\n",
    "    results = get_foursquare_places(lat, lon)\n",
    "    \n",
    "    for r in results:\n",
    "        fsq_pois.append({\n",
    "            \"cluster\": row['cluster'],\n",
    "            \"name\": r.get(\"name\"),\n",
    "            \"category\": r[\"categories\"][0][\"name\"] if r.get(\"categories\") else None,\n",
    "            \"lat\": r[\"latitude\"],\n",
    "            \"lon\": r[\"longitude\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster                             name             category        lat  \\\n",
      "0      0.0          St. Michael's Cathedral               Church  43.655007   \n",
      "1      0.0  Hokkaido Ramen Santouka らーめん山頭火     Ramen Restaurant  43.656435   \n",
      "2      0.0                   Kyoto Katsugyu  Japanese Restaurant  43.656890   \n",
      "3      0.0                  Mackenzie House             Monument  43.655678   \n",
      "4      0.0                    Page One Cafe                 Café  43.657243   \n",
      "5      0.0                     Burrito Boyz   Burrito Restaurant  43.656331   \n",
      "6      0.0                         SukoThai     Asian Restaurant  43.655528   \n",
      "7      0.0                   Ali Basha Cafe           Hookah Bar  43.656728   \n",
      "8      0.0                      Jazz Bistro          Music Venue  43.655678   \n",
      "9      0.0           The Senator Restaurant                Diner  43.655641   \n",
      "\n",
      "         lon  \n",
      "0 -79.377061  \n",
      "1 -79.377586  \n",
      "2 -79.376245  \n",
      "3 -79.378250  \n",
      "4 -79.376021  \n",
      "5 -79.378541  \n",
      "6 -79.374907  \n",
      "7 -79.375378  \n",
      "8 -79.379276  \n",
      "9 -79.379199  \n"
     ]
    }
   ],
   "source": [
    "df_fsq = pd.DataFrame(fsq_pois)\n",
    "print(df_fsq.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Yelp with a small radius (1000m) for all the bike stations in your city of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yelp_data(lat, lon, radius=300):\n",
    "    import requests\n",
    "    api_key = os.getenv('YELP_API_KEY')\n",
    "    YELP_API_KEY = \"your_yelp_api_key\"\n",
    "    url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"radius\": radius,\n",
    "        \"term\": \"restaurant\",\n",
    "        \"limit\": 50\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_data = []\n",
    "\n",
    "#  Apply clustering (e.g., 10 clusters)\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "df['cluster'] = kmeans.fit_predict(coords)\n",
    "\n",
    "# Get centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "cluster_centers = pd.DataFrame(centroids, columns=['latitude', 'longitude'])\n",
    "cluster_centers['cluster'] = cluster_centers.index\n",
    "\n",
    "for _, row in cluster_centers.iterrows():\n",
    "    lat, lon = row['latitude'], row['longitude']\n",
    "    result = get_yelp_data(lat, lon)\n",
    "    \n",
    "    for biz in result.get(\"businesses\", []):\n",
    "        \n",
    "        poi_data.append({\n",
    "            \"cluster\": row['cluster'],\n",
    "            \"name\": biz['name'],\n",
    "            \"category\": biz['categories'][0]['title'] if biz.get(\"categories\") else None,\n",
    "            \"rating\": biz.get(\"rating\"),\n",
    "            \"review_count\": biz.get(\"review_count\"),\n",
    "            \"latitude\": biz['coordinates']['latitude'],\n",
    "            \"longitude\": biz['coordinates']['longitude'],\n",
    "            \"address\": biz['location']['display_address']\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ylp = pd.DataFrame(poi_data)\n",
    "df_ylp.shape[0]\n",
    "# df_ylp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which API provided you with more complete data? Provide an explanation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Four square and Yelp provide the category of the name pf places which is good. But when we compare all the data, Yelp provides more complete data as it includes \n",
    "1. review counts, user ratings of customers\n",
    "2. distance of the location( coverage)\n",
    "3. Detail information about the place like address and business hours "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 restaurants according to their rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As the YELP has detail data we are choosing YELP\n",
    "restaurants_df = df_ylp[df_ylp['category'].str.contains('Restaurant', case=False, na=False)]\n",
    "df_ylp.shape[0]\n",
    "\n",
    "# top10_restaurants = restaurants_df.sort_values(by='rating', ascending=False).head()\n",
    "\n",
    "# top10_restaurants.head(10)\n",
    "# print(top10_restaurants[['name', 'rating', 'review_count', 'address']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
